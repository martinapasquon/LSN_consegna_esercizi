{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d745a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='True' #This is needed in my Anaconda+MacOsX installation; leave it commented.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "seed=0\n",
    "np.random.seed(seed) # fix random seed\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "373f2f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "Y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28 # number of pixels \n",
    "# output\n",
    "num_classes = 10 # 10 digits\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450fea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 784)\n",
      "X_test shape: (10000, 784)\n",
      "\n",
      "an example of a data point with label 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... and with label [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] after to_categorical\n",
      "\n",
      "X_train shape: (60000, 784)\n",
      "Y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# reshape data, it could depend on Keras backend\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows*img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows*img_cols)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print()\n",
    "\n",
    "# cast floats to single precision\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# rescale data in interval [0,1]\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# look at an example of data point\n",
    "print('an example of a data point with label', Y_train[20])\n",
    "# matshow: display a matrix in a new figure window\n",
    "plt.matshow(X_train[20,:].reshape(28,28),cmap='binary')\n",
    "plt.show()\n",
    "\n",
    "# convert class vectors to binary class matrices, e.g. for use with categorical_crossentropy\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "print('... and with label', Y_train[20], 'after to_categorical')\n",
    "print()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "523310fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\n",
    "labels = np.array([0, 2, 1, 2, 0])\n",
    "# `to_categorical` converts this into a matrix with as many columns as there are classes.\n",
    "# The number of rows stays the same.\n",
    "keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65cf8175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture created successfully!\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "def create_DNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(400,input_shape=(img_rows*img_cols,), activation='relu'))\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # soft-max layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "print('Model architecture created successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fa66391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully and ready to be trained.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "\n",
    "def compile_model(opt):\n",
    "    # create the model\n",
    "    model=create_DNN()\n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=opt,\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "print('Model compiled successfully and ready to be trained.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44be141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 15\n",
    "\n",
    "def do_model_DNN(my_optim):\n",
    "\n",
    "  # create the deep neural net\n",
    "  model_DNN = compile_model(my_optim)\n",
    "\n",
    "  # train DNN and store training info in history\n",
    "  history = model_DNN.fit(X_train, Y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(X_test, Y_test))\n",
    "  print('\\n\\n')\n",
    "\n",
    "  # evaluate model\n",
    "  score = model_DNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "  # print performance\n",
    "  print()\n",
    "  print('Test loss:', score[0])\n",
    "  print('Test accuracy:', score[1])\n",
    "\n",
    "  # look into training history\n",
    "\n",
    "  # summarize history for accuracy\n",
    "  plt.plot(history.history['acc'])\n",
    "  plt.plot(history.history['val_acc'])\n",
    "  plt.ylabel('model accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'test'], loc='best')\n",
    "  plt.show()\n",
    "\n",
    "  # summarize history for loss\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "  plt.ylabel('model loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'test'], loc='best')\n",
    "  plt.show()\n",
    " \n",
    "  predictions = model_DNN.predict(X_test)\n",
    "  new_X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols,1)\n",
    "  \n",
    "  plt.figure(figsize=(22, 15)) \n",
    "  for i in range(15):    \n",
    "      ax = plt.subplot(2, 15, i + 1)    \n",
    "      plt.imshow(new_X_test[i, :, :, 0], cmap='gray')    \n",
    "      \n",
    "      plt.title(\"Digit: {}\\nPredicted:{}\".format(np.argmax(Y_test[i]), np.argmax(predictions[i])))    \n",
    "      plt.axis('off') \n",
    "  plt.show()\n",
    "\n",
    "  return model_DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a8dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "#epochs_arr =np.arange(10,50,10)\n",
    "opt='sgd'\n",
    "batch_size=32\n",
    "# create the deep neural net\n",
    "#for i in range(len(epochs_arr)):\n",
    "n_epochs=15\n",
    "model_DNN_sgd = do_model_DNN(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9fe554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score = model_DNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# look into training history\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.ylabel('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0c09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = X_test.reshape(X_test.shape[0], img_rows*img_cols)\n",
    "predictions = model_DNN.predict(X_test)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "plt.figure(figsize=(15, 15)) \n",
    "for i in range(10):    \n",
    "    ax = plt.subplot(2, 10, i + 1)    \n",
    "    plt.imshow(X_test[i, :, :, 0], cmap='gray')    \n",
    "    plt.title(\"Digit: {}\\nPredicted:    {}\".format(np.argmax(Y_test[i]), np.argmax(predictions[i])))    \n",
    "    plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d3cbde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
